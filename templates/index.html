<!DOCTYPE html>
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<html>
  <head>
    <title>SSD Face Detection</title>
  </head>
<style>
canvas {
    padding-left: 0;
    padding-right: 0;
    margin-left: auto;
    margin-right: auto;
    display: block;
    width: 800px;
}
</style>

<body>
    <center>
    <h1>SSD Face detector!</h1>
    <video id="video" hidden="true" autoplay></video>
    <canvas id="canvas"></canvas>
    <br><br>
    <p>
    This website uses <a href="https://arxiv.org/abs/1512.02325">Single Shot Multibox Detector</a> to detect human faces.
    <br>
    <b>How it works under the hood:</b> <br>

    1. It uses JavaScript to ask for Webcam permission, once granted it captures frames and sends them to the Flask backend via an AJAX post request. <br>
    2. The Flask backend captures the incoming frames, uses the SSD model (trained on human selfie images) to detect human faces and returns detected bounding box coordinates. <br>
    3. The ajax call receives the bounding box coordinates and plots them onto the html canvas. <br>
    <p>

    </center>
</body>
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script>

<script>
$(document).ready(function () {

	// Elements for taking the snapshot
	var w = null; var h = null;
	var canvas = document.getElementById('canvas');
	var context = canvas.getContext('2d');
	var video = document.getElementById('video');

	// Get access to the camera!
	if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
	    // Not adding `{ audio: true }` since we only want video now
	    const constraints = {
	    	advanced: [{
	    		facingMode: "environment"
	    	}]
	    };
	    navigator.mediaDevices
	    	.getUserMedia({
	    		video: true  // set it to `constraints` for rear view camera in mobile browser
	    	})
	    	.then(function(stream) {
	        video.srcObject = stream;
	        video.play();
	    });
	}

	setInterval(function(){

		if (video.videoWidth > 0){
			var t0 = performance.now();
			context.drawImage(video, 0, 0, w, h);
				// it takes some time to video to get videowidth.
			w = video.videoWidth;
			h = video.videoHeight;
			if (canvas.width != w){
				console.log('setting canvas dims');
				canvas.height = h;
				canvas.width = w;
				context = canvas.getContext('2d');
			}
			$.ajax({
				async: false,
		    type: 'POST',
		    url: "/postImage",
		    data: {'image': canvas.toDataURL("image/png")},
		    dataType: "text",
		    success: function(resultData) {
		    	// console.log(resultData);
		    	var boxes = JSON.parse("[" + resultData + "]");
                var l = boxes[0].length;
                console.log(boxes[0]);
                var box;
			    for (var i = 0; i < l; i++) {
			    		box = boxes[0][i];
			    		// console.log("box", box);
			    		context.beginPath();
			    		context.strokeStyle="red";
							context.lineWidth="3";
							context.font = "20px Comic Sans MS";
							context.fillStyle = "red";
							context.fillText(box[0].toFixed(2), box[1], box[2]-5);
			        context.rect(
			        	box[1], box[2],
			        	box[3] - box[1],
			        	box[4] - box[2],
			        );
			        context.stroke();
			    }
		    	console.log("Image posted");
		    },
		    error: function(request, status, errror){
		    	console.log(request['status'])
		    }

			});
			var t1 = performance.now();
			console.log("Time taken: " + (t1 - t0) + " ms");
		}
	}, 10);

});
</script>
</html>
